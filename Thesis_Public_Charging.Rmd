---
title: "Thesis_Public_Charging"
author: "Sarah Newton"
date: "2024-02-25"
output: html_document
editor_options: 
  chunk_output_type: console
---
## Libraries and Setup
```{r env_setup, include=FALSE}
## Base packages
library(tidyverse)
library(jsonlite)
library(tmaptools)
library(gtsummary)
library(stargazer)
library(stringr)
library(wesanderson)
library(knitr)
library(rlist)
library(RColorBrewer)
library(spData)
library(ggplot2)
library("ggmagnify")
library(cowplot)
library(rcartocolor)
# Robustness checks
library(broom)
library(car)
library(ggpubr)
library(ivreg)
library(olsrr)

## GiS handling
library(osmdata)
library(sf)
library(googleway)
library(secret)
library(ggmap)

## Routing Analysis
library(sfnetworks)
library(igraph)
library(netdiffuseR)
library(tidygraph)
#remotes::install_github('thomasp85/tidygraph')
library(cppRouting)
library(tidygraph)
library(RANN)
library(nngeo)
library(stplanr)

# Accessibility
library(accessibility)
library(r5r)
#Multi-level model
library(lme4)
library(broom.mixed)
library("insight")
# Network cleaning
library(rgrass)
library(link2GI)
#PCA and Correlation
library('corrr')
library(ggcorrplot)
library(factoextra)

### Enviroment Setup
current_path = rstudioapi::getActiveDocumentContext()$path 
setwd(dirname(current_path))

opts_chunk$set(eval=FALSE,
               include=FALSE,
               echo = FALSE, 
               message = FALSE, 
               warning = FALSE, 
               class.source = "bg-primary")


#### Google Places API key
key <- paste(read_file(paste0(dirname(getwd()), "/gm_api_key.txt")), collapse="\n")
```

```{r load_environment, eval=TRUE}
## Placeholders to be able to save and load heavy datasets and variables
# load('Charge_Environment.RData')
# save.image(file='Charge_Environment.RData')
# save(streets, file="streets.RData")
# save(distances_per_point, file="distances_per_point.RData")
```

## GiS setup and coordinations

```{r gis_setup, include=FALSE}
### Gothenburg subdivisions data

# DeSO subdivisions data from .gpkg
geo <- st_read(dsn="data/DeSO_2018_v2.gpkg")
# ReGSO subdivisioms data from .gpkg
regSO_deso_table <- read_csv2("data/kopplingstabell-deso-regso-20210702.csv")

regSO_deso_table <- regSO_deso_table %>% 
  filter(Kommunnamn == "Göteborg") %>%
  rename(deso = DeSO, regso = RegSO) %>%
  select(deso, regso)

# Create GOT kommon polygon from .gpkg file DeSOs
gothenburg.subdiv <- geo %>% filter(kommunnamn == "Göteborg") #%>% 
# Filter out category A and B deso areas
# https://www.scb.se/hitta-statistik/regional-statistik-och-kartor/regionala-indelningar/deso---demografiska-statistikomraden/
                             #filter(grepl("A", deso) == TRUE)

# Convert Gothenburg subdivision polygons to same crs 4326 as osm data
gothenburg.subdiv <- gothenburg.subdiv %>% st_transform(., 4326)

### OSM data setup
# simple option (not as precise in this case)
# town <- 'Gothenburg' 
# location <- town %>% opq()

# Get GOT boundary using coodinates
coords <- st_bbox(gothenburg.subdiv)
#coords <- matrix(c(11.6, 12.05, 57.63, 57.80), byrow = TRUE, nrow = 2, ncol = 2, dimnames = list(c('x','y'),c('min','max'))) 
location <- opq(st_bbox(gothenburg.subdiv))

# Alternative approach for getting GOT boundary
# Get the boundary for Gothenburg
# got.boundary <- opq(bbox = "Gothenburg, Sweden") %>%
#   add_osm_feature(key = 'admin_level', value = '7') %>% 
#   osmdata_sf %>% unique_osmdata

# got.region <- got.boundary$osm_multipolygons %>% filter(osm_id == '935611')
# 
# neg_buffer <- st_buffer(got.region, -100) # in meters
# got_municipalities_poly <- got.boundary$osm_multipolygons[neg_buffer, ]
```

```{r fetch_road_network_osm, include=FALSE}

# Set the relevant tags and values for each street type needed
main_st <- data.frame(type = c("motorway","trunk","primary","motorway_junction","trunk_link","primary_link","motorway_link"))

st <- data.frame(type = available_tags('highway')$Value)

non_vehicle <- data.frame(type = c("footway", "path", "steps", "cycleway", "corridor", "pedestrian", "track", "bridleway", "bus_guideway", "busway", "bus_stop", "construction", "elevator", "proposed", "street_lamp"))

# Subset by those not in main and non_vehicle streets
st <- subset(st, !type %in% main_st$type & !type %in% non_vehicle$type)

## Save final list as character strings
st <- as.character(st$type)
main_st <- as.character(main_st$type)

# Get all main streets (to be used for plotting)
main_streets <- location %>%
  add_osm_feature(key = "highway", 
                  value = main_st) %>% osmdata_sf()

# Get all other streets (to be used for plotting)
streets <- location %>%
  add_osm_feature(key = "highway", 
                  value = st) %>% osmdata_sf()

### Get all relevant streets all of gothenburg (to be used for the network)
got_streets <- location %>%
                                  # Get all streets and motorways
  add_osm_features(feature = list("highway" = c(main_st, st), 
                                  # Add junctions (roundabouts etc)
                                  "junction" = available_tags('junction')$Value)) %>% osmdata_sf()

### Extra map objects if needed for visualising
# water <- location %>%
#   add_osm_feature(key = "natural", 
#                   value = c("water", "lake", "bay", "strait")) %>% osmdata_sf()
# parks <- location %>% add_osm_feature(key = "leisure", 
#                                       value = c("park","nature_reserve","recreation_ground","golf_course","pitch","garden")) %>%
#                       osmdata_sf()
# forest <- location %>% add_osm_feature(key = "landuse", value = c("forest")) %>%
#  osmdata_sf()
# 
# land <- location %>%
#   add_osm_feature(key = "natural", 
#                   value = available_tags('natural')$Value) %>% osmdata_sf()

```

## Methods

### Create network graph

```{r setup_network_graph_old, include=FALSE}
##### Preparing Graph of nodes and edges #####

# ### Bind the relevant streets and paths into one set 
# got_streets <- rbind((streets$osm_lines %>% select(highway)), 
#                      main_streets$osm_lines %>% select(highway))
# 
# # Give each edge a unique index
# edges <- got_streets %>% 
#   select(highway) %>%
#   mutate(edgeID = c(1:n()))
# 
# # Create nodes at the start and end point of each edge
# nodes <- edges %>%
#   st_coordinates() %>%
#   as_tibble() %>%
#   rename(edgeID = L1) %>%
#   group_by(edgeID) %>%
#   slice(c(1, n())) %>%
#   ungroup() %>%
#   mutate(start_end = rep(c('start', 'end'), times = n()/2))
# 
# # Give each node a unique index
# nodes <- nodes %>%
#   mutate(xy = paste(.$X, .$Y)) %>% 
#   mutate(nodeID = group_indices(., factor(xy, levels = unique(xy)))) %>%
#   select(-xy)
# 
# # Combine the node indices with the edges
# source_nodes <- nodes %>%
#   filter(start_end == 'start') %>%
#   pull(nodeID)
# 
# target_nodes <- nodes %>%
#   filter(start_end == 'end') %>%
#   pull(nodeID)
# 
# # Merge source nodes and target nodes
# edges <- edges %>%
#   mutate(from = source_nodes, to = target_nodes)
# 
# # Remove duplicate nodes
# nodes <- nodes %>%
#   distinct(nodeID, .keep_all = TRUE) %>%
#   select(-c(edgeID, start_end)) %>%
#   st_as_sf(coords = c('X', 'Y')) %>%
#   st_set_crs(st_crs(edges))
# 
# # Create a graph from the adjacency matrix
# graph <- tbl_graph(nodes = nodes, edges = as_tibble(edges), directed = FALSE)
# 
# # Identify isolate nodes in the graph
# # isolated(as_adjacency_matrix(graph)) %>% as_tibble() %>% filter(value==TRUE)
# 
# # The activate() verb specifies if we want to manipulate the edges or the nodes. 
# graph <- graph %>%
#   activate(edges) %>%
#   filter(!edge_is_multiple()) %>%
#   filter(!edge_is_loop()) %>%
#   mutate(length = st_length(geometry))
# 
# # Subdivide the edges
# graph <- convert(graph, to_spatial_subdivision)
# # Smooth
# # Smoothing reduces precision so will not use
# # graph <- convert(graph, to_spatial_smooth, summarise_attributes = list(length = "sum"))
# 
# graph %>% activate(edges) %>% as_tibble() %>% filter(is.na(length))# %>% st_as_sf()
# # graph <- graph %>% activate(edges) %>% as_tibble() %>% filter(!is.na(length)) %>% st_as_sf()

```

```{r setup_network_graph}
##### Preparing the road network graph of nodes and edges #####
# Turn return polygons to linestrings
 poly_to_lines <- st_cast(got_streets$osm_polygons, "LINESTRING")
# bind all lines together
 got_streets.lines <- bind_rows(got_streets$osm_lines, poly_to_lines)
 
# Select just the "highway" and "junction" values of the osmlines as the rest are not needed in the network
got_streets.lines <- got_streets.lines %>% select(highway, junction, maxspeed)

got_streets_net <- as_sfnetwork(got_streets.lines, directed = FALSE)

# Filter the network by the true Gothenburg subdivision polygon
got_streets_net <- got_streets_net %>% st_filter(., gothenburg.subdiv, .predicate = st_intersects)

# Check the CRS to ensure it's correct before continuing: EPSG:4326
# st_crs(got_streets_net)

# Use the “spatial morpher” function to create a subdivision of edges
got_streets_net <- convert(got_streets_net, to_spatial_subdivision)

# Further cleaning
got_streets_net <- got_streets_net %>% 
  activate("edges") %>% 
  # Remove looping edges and repeated edges
  filter(!edge_is_multiple()) %>%
  filter(!edge_is_loop()) %>%
  # add length of edges as a new variable
  mutate(length = edge_length()) %>%
  # Some values for maxspeed ar NA. Control for this by taking the mean.
  mutate(maxspeed = ifelse(is.na(as.integer(maxspeed)), mean(as.integer(E(got_streets_net)$maxspeed), na.rm=TRUE), maxspeed)) %>%
  # Convert distance to kilometres
  mutate(distance.km = as.numeric(length) / 1000) %>%
  # Set the time taken to traverse the edge based on max speed
  mutate(time = distance.km * 100 / as.integer(maxspeed))

# Remove "islands" of nodes and edges isolated from the wider road network.
# Threshold is set to 6
# !!! This is a problematic way to remove islands and could cause disruptions in the wider network. 
# Instead, use Components below
# got_streets_net <- got_streets_net %>% 
#   activate(nodes) %>% 
#   mutate(neighbourhood = local_size(order = 6)) %>% 
#   filter(neighbourhood > 5)
##got_streets_net.unfiltered <- got_streets_net.unfiltered %>% activate(edges) %>% mutate(edge_id = c(1:n()))

# Check the number of components in the network (Number of isolated islands not connected to the main network)
#https://igraph.org/r/doc/components.html
components <- got_streets_net %>% components(., mode = c("weak", "strong"))
components$csize %>% as_tibble() %>% rownames_to_column(., "component") %>% count(value) %>% arrange((value))
components$csize %>% as_tibble() %>% rownames_to_column(., "component") %>% arrange(desc(value))

got_streets_net <- got_streets_net %>% activate(nodes) %>% mutate(component = components$membership)

# After validating the component results, all components aside from 1 contained areas that were not used in this analysis, such as isolated industrial access roads and private access roads or access paths
# !! Västra Lindås becomes isolated from the network when filtering on the GOT boundaries. May need to fix this, or cater for that when discussing the results
got_streets_net <- got_streets_net %>% activate(nodes) %>% filter(component == 1)

# Add an "id" to each node in the network based on rowname index
# !!Make sure that this is the last step done to the network otherwise filtering and other mutations may impact the correctness of this.
got_streets_net <- got_streets_net %>% 
  activate("nodes") %>% 
  mutate(id = c(1:n()))
```

```{r nodes_to_coords_matrix}
### Convert nodes to coordinates matrix
got_streets.df <- got_streets_net %>%
  activate(nodes) %>%
  as_tibble()

got_streets.sf <- got_streets.df %>% st_as_sf()

### Convert nodes to coordinates matrix
got_streets_coords <- got_streets_net %>%
  activate(nodes) %>%
  as_tibble() %>% st_as_sf() %>%
  st_coordinates()
```

### Charging points
```{r p2p_charge_points, include=FALSE}

# Data from 'Open Street Maps'
# Gets data from OSM api
charging_stations.osm <- location %>%
  add_osm_feature(key = "amenity", 
                  value = "charging_station") %>% osmdata_sf() 

# Filter by Gothenburg boundaries 
charge_points.osm <- charging_stations.osm$osm_points %>% st_filter(., gothenburg.subdiv)

# Additional data scraping as more points were found here. Will be joined later on

## Data from "Place to Plug" website
## Scraped from Placetoplug.com 31-01-2024
## Address: https://placetoplug.com/en/charging-stations/Sweden/Gothenburg/1
## Search term Gothenburg, Sweden
## 380 results, 38 pages.

json <- jsonlite::fromJSON(txt="data/Charging_Points-place-to-plug.json")
p2p.data <- json$chargingZones

p2p.data <- p2p.data %>% select(id, name, address, isFastCharge, powerRange, plugTypes, status, vehicleTypes, -`__typename`)
p2p.data <- p2p.data %>% mutate(full_address = gsub(" , ", "", paste(ifelse(is.na(address$street), name, address$street), 
                                         address$city, 
                                         address$subdivision)))
# Generate thecharge point details url
getDetailsUrl <- function (x) {
  return(paste0("https://placetoplug.com/en/charging-stations/Sweden/", 
                x$full_address, "/", 
                x$id, "/", 
                str_replace(x$name, " ", "_")))
  
}
p2p.data <- p2p.data %>% mutate(url = getDetailsUrl(.))

# Example of charge point demographics that are available
ex.chargepoint.demographics <- fromJSON("data/test_charge_details.json")
#view(ex.chargepoint.demographics$data$chargingZone$stations %>% as_tibble())

# Set up for the google api key for ggmap on first use:
# register_google(key = key, write=TRUE)

# Fetch long and lat for the charging point
# p2p.long_lat <- geocode(tolower(p2p.data$full_address))
# Write to csv for easier use later
# write_csv(p2p.long_lat, "data/p2p_data_long_lat.csv")

# Read in Place 2 Plug data from the saved csv
p2p.long_lat <- read_csv("data/p2p_data_long_lat.csv")
p2p.data <- p2p.data %>% mutate(p2p.long_lat)
# Plug types
#IEC_62196_T2
#IEC_62196_T2_COMBO
#CHADEMO
#OTHER
#DOMESTIC_F
#TESLA_S_EU

# Clean data
p2p.data <- p2p.data %>% mutate(vehicleTypes.car = ifelse(grepl("CAR", p2p.data$vehicleTypes), TRUE, FALSE),
                                vehicleTypes.bike = ifelse(grepl("BICYCLE", p2p.data$vehicleTypes), TRUE, FALSE),
                                vehicleTypes.motorbike = ifelse(grepl("BIKE", p2p.data$vehicleTypes), TRUE, FALSE),
                                status = factor(status),
                                powerRange.min = as.numeric(p2p.data$powerRange$min),
                                powerRange.max = as.numeric(p2p.data$powerRange$max))

p2p.data <- p2p.data %>% na.omit(powerRange.min, powerRange.max) %>% select(id, full_address, lon, lat, status,
                                             vehicleTypes.car, vehicleTypes.bike, vehicleTypes.motorbike, 
                                             isFastCharge, powerRange.min, powerRange.max
                                              )
p2p.data <- p2p.data %>% mutate(lng = lon) %>% filter(powerRange.min > 0)
# Filter out charge points outside of Gothenburg coords
p2p.data <- p2p.data %>% filter(between(lng, coords[1], coords[3]) &
                                                    between(lat,coords[2], coords[4]))

charge_points.p2p <- p2p.data %>% filter(vehicleTypes.car == TRUE) %>% select(-status, -vehicleTypes.bike, -vehicleTypes.motorbike)# %>% select(lat, lng)

charge_points.p2p.geo <- st_as_sf(charge_points.p2p, 
                                  coords = c("lng", "lat"), crs = 4326)

# Convert Gothenburg subdivision polygons to same crs 4326 as osm data
gothenburg.subdiv <- gothenburg.subdiv %>% 
  mutate(area = st_area(.)) %>%
  st_as_sf(., coords = c("x","y"), crs = 4326)

# spatial join of subdivisions and charge points
charge_points.p2p.geo <- st_filter(charge_points.p2p.geo, gothenburg.subdiv)

### Convert charging points to coordinates matrix
charge_points.long_lat.matrix <- as.matrix(st_coordinates(charge_points.p2p.geo)) %>% na.omit()

# Save cleaned and merged data as csv
# write_csv(p2p.long_lat, "p2p_data_long_lat.csv")
# write_csv(p2p.data, "p2p_data_complete.csv")
# p2p.data <- read_csv("p2p_data_complete.csv")

```

### Snap charge points to nodes

```{r snap_points_to_nodes, include=FALSE}
# Function for getting the node id of a charge point
getNodePoint <- function(chargeId) {
  i <- match(chargeId, charge_points.p2p.geo.nodes$charge_id)
  # Get nodeID of the point to snap to
  snap_node <- as.integer(charge_points.p2p.geo.nodes[i,]$nodeId)
  #print(paste(charge, i, snap_node, snap_point_id))
  return(snap_node)
}

# Function for getting the charge id of a charge point
getChargePoint <- function(chargeId) {
  i <- match(chargeId, charge_points.p2p.geo.nodes$charge_id)
  # Get nodeID of the point to snap to
  charge_node <- as.integer(charge_points.p2p.geo.nodes[i,]$charge_id)
  #print(paste(charge, i, snap_node, snap_point_id))
  return(charge_node)
}

### Snap charging points to nodes
# Alternative. nearest_feature https://cran.r-project.org/web/packages/sfnetworks/vignettes/sfn03_join_filter.html
#charge_point.coords <- charge_points.long_lat.matrix %>% as_tibble() %>% st_as_sf(coords = c("X", "Y"), crs = 4326)

# Find indices of nearest nodes.
nearest_nodes <- st_nearest_feature(charge_points.p2p.geo, got_streets_net)

# Snap geometries of charge points to the network.
charge_points.p2p.geo.nodes <- charge_points.p2p.geo %>% 
  st_set_geometry(st_geometry(got_streets_net)[nearest_nodes]) %>% 
  mutate(nodeId = nearest_nodes)

```

### Merge charge point data

```{r join_chargepoint_data, include=FALSE}
# Filter out private access charge points
charge_points.osm <- charge_points.osm %>% filter(access != "private")

# Total OSM charge points
charge_points.osm %>% nrow()
# Total P2P charge points
charge_points.p2p.geo %>% nrow()

# Get nearest nodes in the pre-snapped P2P charge point data
nearest_nodes.osm <- st_nearest_feature(charge_points.osm, charge_points.p2p.geo.nodes)

charge_points.osm.nodes <- charge_points.osm %>% 
  st_set_geometry(st_geometry(charge_points.p2p.geo.nodes)[nearest_nodes.osm]) %>% 
  mutate(nodeId = nearest_nodes.osm)

charge_points.osm.nodes.df <- charge_points.osm.nodes %>% as.data.frame()
charge_points.p2p.geo.nodes.df <- charge_points.p2p.geo.nodes %>% as.data.frame() %>% rownames_to_column(., "charge_id")

joined_charge_points <- merge(charge_points.osm.nodes.df, charge_points.p2p.geo.nodes.df, by.x="nodeId", by.y="charge_id", all.y = TRUE)

median_cap <- median(as.integer(joined_charge_points$capacity), na.rm = TRUE)

joined_charge_points <- joined_charge_points %>% 
  # Add capacity values and include the media (4) as default if NA
  mutate(capacity = as.integer(ifelse(is.na(capacity), median_cap, capacity))) %>% 
  # Rename geometry and remove duplicates
  mutate(geometry = geometry.y) %>% 
  select(-geometry.x, -geometry.y) %>% st_as_sf()

#joined_charge_points <- st_join(charge_points.p2p.geo.nodes, charge_points.osm.nodes, left=TRUE)

# capacities <- joined_charge_points %>% 
#   mutate(capacity = as.integer(ifelse(is.na(capacity), 1, capacity))) %>%
#   # Change NA capacity to 1
#   group_by(nodeId.x) %>% 
#   summarise(capacity = sum(capacity)) %>% arrange(nodeId.x)
joined_charge_points %>% distinct(nodeId)
  
joined_charge_points <- joined_charge_points %>%
  #distinct(nodeId.x, .keep_all = TRUE) %>%
  rename(chargeId = "nodeId", nodeId = "nodeId.y") %>% 
  arrange(nodeId) %>%
  st_as_sf()

# As a final step, set the charge point id of the final charge point data based on row name
# Add row names as charge point ids
joined_charge_points <- joined_charge_points %>% rownames_to_column(., "charge_id")

# Total charging stations
joined_charge_points %>% nrow()

# Total charging capacity of all charging stations
sum(joined_charge_points$capacity)
```

```{r plot_network_graph, eval=TRUE, include=TRUE}
# Plot to snap points versus the original points to validate result
ggplot() +
  geom_sf(data = got_streets_net %>% activate(edges) %>% as_tibble() %>% st_as_sf(), linewidth = 0.2, color="#1e00be") + 
  geom_sf(data = got_streets_net %>% activate(nodes) %>% as_tibble() %>% st_as_sf(), size=0.1, color="#1e00be") +
  geom_sf(data=gothenburg.subdiv, alpha=0.4, linewidth=0.5, colour="#8778D7", fill="#A753AF") +
  geom_sf(data = joined_charge_points, size=3, aes(color=capacity)) +
  geom_sf(data = charge_points.p2p.geo, size=0.9, color="red") +
  labs(x="", y="") +
  theme_minimal() + theme(legend.position = "")
```

### KNN Euclidean distance

Calculate the closest charge point to a node/intersection using K nearest neighbour (5). This method is the simplest measure for calculating distance, but does NOT take into consideration the surrounding road network

```{r setup_knn_nearest_point}
#### FINDING NEAREST CHARGE POINTS #####

### As the crow flies method (Euclidean distance)
knn.sf <- nngeo::st_nn(x = got_streets_net %>% activate(nodes), 
             y = joined_charge_points,
             k = 5,
             sparse = TRUE,
             returnDist = TRUE,
             # Set a max distance for the knn search to 20km
             maxdist = 20000,
             progress = TRUE)

getMinKnn.sf <- function(i, ids, distances) {
  # Transpose the distance and nn data
  dist_trans <- t(unlist(distances[i]) %>% as.matrix())
  # get the index of min knn distance found
  min_dist_i <- which.min(dist_trans)
  # Prepare the knn point id
  id_trans <- t(unlist(ids[i]) %>% as.matrix())
  #print(paste(id_trans[min_dist_i], dist_trans[min_dist_i]))
  return(data.frame(id_trans[min_dist_i], dist_trans[min_dist_i]))
}

closest_charge_sf <- data.frame()
for (i in 1:length(knn.sf$nn)) {
  #print(paste("running:", i,  "of", as.character(nrow(knn.3$nn.idx))))
  new_elements <- getMinKnn.sf(i, knn.sf$nn, knn.sf$dist)
  closest_charge_sf <- rbind(closest_charge_sf, new_elements)
}

colnames(closest_charge_sf) <- c("charge_id", "distance")
got_streets_net.knn <- cbind(got_streets_coords, closest_charge_sf) %>% 
  mutate(Lon = X, Lat = Y) %>% select(-X, -Y)

# 
# knn.sf.nodes <- nngeo::st_nn(x = joined_charge_points, 
#              y = got_streets_net %>% activate(nodes),
#              k = 5,
#              sparse = TRUE,
#              returnDist = TRUE,
#              # Set a max distance for the knn search to 20km
#              maxdist = 20000,
#              progress = TRUE)
# 
# closest.sf.nodes <- data.frame()
# for (i in 1:length(knn.sf.nodes$dist)) {
#   new_elements <- getMinKnn.sf(i, knn.sf.nodes$nn, knn.sf.nodes$dist)
#   closest.sf.nodes <- rbind(closest.sf.nodes, new_elements)
# }
# 
# colnames(closest.sf.nodes) <- c("node_id", "distance")
```

```{r snap_points_to_nodes_Manual, include=FALSE}
# Create a simple matrix of snap points based on the closest node calculated using knn above
# snap_matrix <- closest.sf.nodes %>%
#   rownames_to_column(., var = "charge_id") %>%
#   select(node_id, charge_id)
# 
# # Function: Based on the closest network node to a charge point, get snap point geometry
# getSnapPoint <- function(node) {
#   i <- match(node, snap_matrix[,2])
#   snap_node <- as.integer(snap_matrix[i,]$node_id)
#   snap_point <- got_streets.df[snap_node,]$geometry
#   return(snap_point)
# }
# 
# # Check to ensure working function and no NAs
# # na_charge_list <- data.frame()
# # checkNa <- function(charge) {
# #   i <- match(charge, snap_matrix[,2])
# #   snap_node <- as.integer(snap_matrix[i,]$node_id)
# #   snap_point_id <- got_streets.sf[snap_node,]$nodeID
# #   return(data.frame(snap_node, charge))
# # }
# #
# # for (i in 1:nrow(charge_points.p2p.geo)) {
# #   new_elements <- checkNa(charge_points.p2p.geo$charge_id[i])
# #  # To check which values are null
# #   na_charge_list <- ifelse(is.na(new_elements[1]),
# #        rbind(na_charge_list, new_elements[2]), na_charge_list)
# # }
# # na_charge_list <- na_charge_list[[1]]
# 
# # Function: Based on the closest network node to a charge point, get snap point node id
# getNodePoint <- function(charge) {
#   i <- match(charge, snap_matrix[,2])
#   # Get nodeID of the point to snap to
#   snap_node <- as.integer(snap_matrix[i,]$node_id)
#   #print(paste(charge, i, snap_node, snap_point_id))
#   return(snap_node)
# }
# 
# # Node ids: Mutate the existing charge point data using the above functions
# charge_points.p2p.geo.nodes <- charge_points.p2p.geo %>%
#   mutate(nodeId = mapply(getNodePoint, charge_id)) %>%
#   select(charge_id, nodeId) %>%
#   as_tibble() %>%
#   st_as_sf(crs = 4326)
# 
# # Snap point geometry: Mutate the existing charge point data using the above functions
# charge_points.p2p.geo.snaps <- charge_points.p2p.geo %>%
#   mutate(geometry = mapply(getSnapPoint, charge_id)) %>%
#   select(charge_id, geometry) %>%
#   as_tibble() %>%
#   st_as_sf(crs = 4326)
```


### Dijkstra's graph search (shorted path)

Alternative more "accurate" measure for shortest paths what considering road networks and driveability.

```{r loop_dijkstras_charge_points}
# https://github.com/ropensci/stplanr/issues/261 Talking about issues with stplanr
# Loop over each charge point node and find the shortest path from a charge point to a nearby node
cp.test <- charge_points.p2p.geo.nodes %>% na.omit()

test <- data_frame()
for(i in 1:nrow(cp.test)) {
  # select closest nodes
  closest_nodes <- knn.3.nodes$nn.idx[i,] %>% as_tibble() %>% filter(value != cp.test[i,]$nodeId)
  print(paste("Start:", cp.test[i,]$charge_id))
  # loop to get shortest path for each
  for(ii in 1:nrow(closest_nodes)) {
    from_cp_node <- got_streets_net.merged %>%
                    activate(nodes) %>%
                    filter(id == cp.test[i,]$nodeId) %>%
                    pull(id)
    
    to_node <- got_streets_net.merged %>%
                    activate(nodes) %>%
                    filter(id == as.character(closest_nodes[ii,])) %>%
                    pull(id)
      
    # print(paste("from node:", from_cp_node, "to node:",  to_node))
      path <- shortest_paths(
              graph = got_streets_net.merged,
              from = from_cp_node,
              to = to_node,
              #mode = "all",
              output="both",
              algorithm ="dijkstra", # Ensure to use Dijkstra's algorithm
              weights = got_streets_net.merged %>% activate(edges) %>% pull(length)
            )
      
    path_graph <- got_streets_net.merged %>%
                  subgraph.edges(eids = path$epath %>% unlist()) %>%
                  as_tbl_graph()
    
   distance_data <- path_graph %>%
          activate(edges) %>%
          as_tibble() %>%
          summarise(length = sum(length))
   
    print(paste("Distance:", distance_data))
    new_distances <- data_frame(data_frame(from_cp_node, to_node, distance_data))
    test <- rbind(test, new_distances)
  }
  
  print("")
}

dijkstras_cp_to_node <- test
colnames(dijkstras_cp_to_node) <- c("from_node", "to_node", "distance")
view(dijkstras_cp_to_node.avg)

# Group by the change point and get average distance to surrounding nodes
dijkstras_cp_to_node.avg <- dijkstras_cp_to_node %>% 
  group_by(from_node) %>% 
  summarise(avg_travel_dist = mean(distance)) %>% 
  arrange(avg_travel_dist)
```


#### Testing and plotting
```{r dijkstras_graph_search_tests}
####--- This code is reserved for point to point shortest path testing and visualisation
# https://cran.r-project.org/web/packages/sfnetworks/vignettes/sfn03_join_filter.html
# From node is the charge point

time_per_point %>% filter(time > 1) %>% arrange(time)
# 1      30032     688  1.00     402.
#  2     26115   49506  1.00     454.
#  3      2166   40608  1.00     492.
test_from_node <- got_streets_net %>%
  activate(nodes) %>%
  filter(id == 2166) %>%
  pull(id)

# to node is the closest node in the network 
test_to_node <- got_streets_net %>%
  activate(nodes) %>% 
  filter(id == 40608) %>%
  pull(id)

# Get the shortest path between each of these points
      test_path <- shortest_paths(
                graph = got_streets_net,
                from = test_from_node,
                to = test_to_node,
                #mode = "all",
                output="both",
                algorithm ="dijkstra", # Ensure to use Dijkstra's algorithm
                weights = got_streets_net %>% activate(edges) %>% pull(length)
              )
    test_path_graph <- got_streets_net %>%
                    subgraph.edges(eids = test_path$epath %>% unlist()) %>%
                    as_tbl_graph()
    
test_path_graph %>%
          activate(edges) %>%
          as_tibble() %>%
          summarise(length = sum(length))

nodes.df <- got_streets_net %>% activate(nodes) %>% filter(id %in% c(test_from_node, test_to_node)) %>% as_tibble() %>% cbind(tibble(name =c("Origin", "Charging station")))

test_filtered.bb <- st_filter(got_streets_net, test_path_graph %>% as_tibble() %>% st_as_sf()) %>% st_bbox()
# Plot reserved for testing single shortest paths
ggplot() +
  # DeSO Subdivisions
  # geom_sf(data = gothenburg.subdiv, alpha=0.6, linewidth=0.6, colour="#8778D7", fill="#90C59B") + 
  # Road network edges
  # geom_sf(data = got_streets_net %>% activate(nodes) %>% as_tibble() %>% st_as_sf(), size = 1, col = 'grey') +
  geom_sf(data = got_streets_net %>% activate(edges) %>% as_tibble() %>% st_as_sf(), size = 2.5, col = 'grey') +
  # Road network nodes
  geom_sf(data = joined_deso.nodes, size=2, col="dark gray") +
  # Label nodes
  #geom_sf_label(data= sample.nodes, label=sample.nodes$nodeID) +
  # Dijkstra's paths
   geom_sf(data = test_path_graph %>% activate(edges) %>% as_tibble() %>% st_as_sf(), lwd = 1.5, col = '#bb3e03') +
   # charge points
   geom_sf(data = got_streets_net %>% activate(nodes) %>% as_tibble() %>% filter(id %in% c(test_from_node, test_to_node)), size = 3.8, col = '#3B9AB2') +
   geom_sf_text(data = got_streets_net %>% activate(nodes) %>% as_tibble() %>% filter(id %in% c(test_from_node, test_to_node)), 
                label = nodes.df$name, 
                col="black", 
                fill="#94d2bd",
                label.size = 5, 
                nudge_x = 0.0006) +
  # Coordinates of path 1
    # coord_sf(xlim = c(11.9265, 11.938),
    #        ylim = c(57.669, 57.6740),
    #        expand = TRUE, clip = "on") +
# Coordinates of path 2
    coord_sf(xlim = c(test_filtered.bb$xmin, test_filtered.bb$xmax),
          ylim = c(test_filtered.bb$ymin, test_filtered.bb$ymax),
          expand = TRUE, clip = "off") +
    # # Coordinates of path 3
    # coord_sf(xlim = c(11.925, 11.945),
    #        ylim = c(57.669, 57.6440),
    #        expand = TRUE, clip = "on")
    theme_void()


```

#### Run Dijkstra's function
```{r loop_dijkstras_nodes}
### !! Note: This functions takes about 4 hours to complete !! 
### Read the pre-generated data already exported from the csv:
#distances_per_point <- read_csv("data/dijkstras_per_point.csv")
#time_per_point <- read_csv("data/dijkstras_time_per_point.csv")

## Loop over each node in the entire road network and find the shortest path to a charge point
all_nodes <- got_streets_net %>% activate(nodes) %>% as_tibble()

# define the weights to use. In this case time to destination
path_weights <- got_streets_net %>% activate(edges) %>% pull(time)

# Set the empty df for storing each distance result
time_per_point <- data_frame()

# Start timer
start.time <- Sys.time()
for(i in 1:nrow(all_nodes)) {
  # select current node in iteration
  current_node <- all_nodes[i,]$id
  print(paste("Running:", current_node))
  # Get closest charge point
  closest_cp <- joined_charge_points %>% 
    as_tibble() %>% 
    filter(charge_id == closest_charge_sf[current_node,]$charge_id)
  # If not found, skip to next item
  ifelse(nrow(closest_cp) == 0, next, NA)
  print(paste("charge point:", closest_cp$charge_id))
    # get shortest path for the current node to it's closest charge point
    from_node <- got_streets_net %>%
                    activate(nodes) %>%
                    filter(id == current_node) %>%
                    pull(id) # ! It would be safer to use the vertex index here otherwise it can easily be broken if changes are made to the network graph, such as filtering as the shortest_path algorithm does not use the node attribute "id" col, but it's index.
    
    to_node <- got_streets_net %>%
                    activate(nodes) %>%
                    filter(id == closest_cp$nodeId) %>%
                    pull(id)
      
    print(paste("from node:", from_node, "to node:",  to_node))

      path <- shortest_paths(
                graph = got_streets_net,
                from = from_node,
                to = to_node,
                #mode = "all",
                output="both",
                algorithm ="dijkstra", # Ensure to use Dijkstra's algorithm
                weights = path_weights
              )
    path_graph <-  got_streets_net %>%
                   subgraph.edges(eids = path$epath %>% unlist()) %>%
                   as_tbl_graph()
    
   distance_data <- path_graph %>%
          activate(edges) %>%
          as_tibble() %>%
          summarise(length = sum(length))
   time_data <- path_graph %>%
          activate(edges) %>%
          as_tibble() %>%
          summarise(time = sum(time))
   
    print(paste("Distance:", distance_data, "Time", time_data))
    new_distances <- tibble(from_node = from_node, to_node = to_node, time = time_data$time, distance = distance_data$length)
    time_per_point <- rbind(time_per_point, new_distances)
  print("")
  print(paste(scales::percent(current_node / nrow(all_nodes)), "complete"))
  print("")
}

end.time <- Sys.time()
time.taken <- round(end.time - start.time, 2)
time.taken

# # Set column names
#colnames(distances_per_point) <- c("from_node", "to_node", "distance")
view(time_per_point)

time_per_point %>% group_by(ifelse(as.integer(distance) == 0, "Failed", "Succeeded")) %>% summarize(n= n())

# Save as csv for backup as the function takes 6 hours to run and you do not want to risk R crashing...
write_csv(time_per_point, "data/dijkstras_time_per_point.csv")

```

```{r clean_dijkstras_data}
# Merge with the road network data by from_node id to get the geometry values. Cast to sf network.
distances_per_point.sf <- merge(time_per_point,
                                got_streets_net %>% activate(nodes) %>% as_tibble(), 
                                by.x="from_node", by.y="id", 
                                all=TRUE) %>% arrange(from_node) %>% st_as_sf()

# Add the knn distances and associated charging point id to the sf
distances_per_point.sf <- distances_per_point.sf %>%
  mutate(chargeId = closest_charge_sf$charge_id, 
         knn_distance = closest_charge_sf$distance,
         travel_time = time,
         dijkstras_distance = distance) %>%
  select(from_node, to_node, chargeId, travel_time, dijkstras_distance, knn_distance, everything(), -distance)

# Filter out nodes that are the same as the corresponding charge point as this distance is of course zero.
#distances_per_point.sf %>% view()
distances_per_point.sf %>% filter(from_node == to_node)

# Filter the nodes to the GOT DeSOs to remove those that fall outside. This is just used for this initial plotting
filtered <- st_filter(distances_per_point.sf, gothenburg.subdiv)
filtered %>% filter(is.na(to_node)) %>% nrow()
# Plot the data so far
ggplot() +
  # All road network nodes
  #geom_sf(data = got_streets_net %>% activate(nodes) %>% as_tibble() %>% st_as_sf(), size=0.4) +
  # nodes coloured by distance
  geom_sf(data=filtered, size=0.5, aes(color=scale(travel_time, center = TRUE))) +
  # Charge points
  geom_sf(data=joined_charge_points, col="blue") +
  # DeSO Subdivisions
  geom_sf(data = gothenburg.subdiv, alpha=0.3, linewidth=0.6, colour="#8778D7", fill=NA) + 
  scale_color_distiller(palette = "Oranges") + theme_void()
```


### Accessibility measures

Using a measure for potential accessibility by distance decay. Operationalized as a negative exponential function for surrounding nodes

```{r prepare_data_accessibility, include=FALSE}
# https://cran.r-project.org/web/packages/accessibility/vignettes/accessibility.html
# Setup network to be compatible for accessibility functions. This requires:
# 1. A distance travel matrix (distances for each of the from and to points)
# 2. A land use data set so identify which points contain a charge point. Used for determining accessibility

# Setup a distance travel matrix using all nodes and the distance to their knn nearest charge point
distance_travel_matrix <- closest_charge_sf %>% 
  rownames_to_column(., var = "node_id") %>%
  mutate(charge_node_id = mapply(getNodePoint, charge_id)) %>%
  mutate(from_id = node_id, 
         to_id = charge_node_id, 
         length = distance,
         from_to = paste0(from_id, ":", to_id)) %>% 
  select(from_id, to_id, length, from_to)

# Create an additional travel matrix using the dijkstras shortest paths distance for comparison
distance_travel_matrix_dijk <- distances_per_point.sf %>% 
  mutate(from_to = paste0(from_node, ":", to_node))

distance_travel_matrix_dijk <- distance_travel_matrix_dijk %>% 
  st_join(., gothenburg.subdiv) %>%
  mutate(from_id = from_node, to_id = to_node, 
         distance = as.numeric(dijkstras_distance),
         travel_time = as.numeric(travel_time)
         ) %>%
  select(from_id, to_id, length, travel_time, deso) %>% as_tibble()

# Group duplicate locations together and combine the capacities
grouped_charge_points <- joined_charge_points %>% 
  count(nodeId, capacity) %>% 
  as_tibble() %>% 
  select(nodeId, capacity, -geometry) %>% 
  group_by(nodeId) %>% 
  summarise(capacity = sum(capacity))

### TODO
### Get the number of chargers per point here, rather than defaulting to 1
got_streets_net.with_charge <- got_streets_net %>% 
  activate(nodes) %>% 
  # Get charge point capacity
  mutate(charge_points = as.numeric(
    ifelse(id %in% grouped_charge_points$nodeId, 
                   grouped_charge_points[match(id, grouped_charge_points$nodeId),]$capacity,
                   0)
    )
  )  

# Check how many charge points are connected for validation
got_streets_net.with_charge %>% activate(nodes) %>% filter(charge_points > 0)

# Create a Land use data frame
charge_land_use <- got_streets_net.with_charge %>% 
  as_data_frame(., what="vertices") %>%
  select(id, charge_points)

charge_land_use %>% filter(charge_points > 0)

```

#### Run accessibility function
```{r potential_accessibility_func, include=FALSE}
# Potential function (distance decay)
# The potential accessibility
# measure estimates the accessibility of opportunities in zone i to all other zones (n) in which smaller and/or more distant opportunities provide diminishing influences. The measure has the following form, assuming a negative exponential cost function:

# Run the same but for the travel matrix using dijkstras distance
negative_exp_dijk <- gravity(
    distance_travel_matrix_dijk,
    charge_land_use,
    opportunity = "charge_points",
    travel_cost = "distance",
    # Negative exponential cost function
    decay_function = decay_exponential(decay_value = 0.1)
  )

view(negative_exp_dijk)
negative_exp_dijk %>% filter(charge_points == 0)

#The research also revealed 97% of people who do not yet own an EV would be willing to travel up to five miles to access a charging point for their EV, yet just under half (44%) were not confident they could find a public EV charging point within this distance.
#https://midlandsengine.org/news-events/consumer-research-shows-lack-of-electric-vehicle-charge-points-a-barrier-for-uptake/
# Culmulative count accessibility
culm_count <- accessibility::cumulative_cutoff(travel_matrix = distance_travel_matrix_dijk,
                                 land_use_data = charge_land_use,
                                 opportunity = 'charge_points',
                                 travel_cost = 'travel_time',
                                 cutoff = 8)
```

### Avg distance by DeSO 

#### Spatial Join and merge node and distance averages
```{r merge_nodes_to_desos, include=FALSE}
# Get averages and spatial join the distance values with the nodes and GIS data

# Join the nodes to the GOT DeSOs to for the next stage of DeSO analysis
joined_deso.nodes <- st_join(distances_per_point.sf, gothenburg.subdiv, join = st_within, left=TRUE)

##Merge in the distance decay accessibility values
joined_deso.nodes <- merge(joined_deso.nodes,
                        negative_exp_dijk,
                        by.x="from_node",
                        by.y="id",
                        all=TRUE) %>%
  rename(potential_accessibility = "charge_points") %>%
  merge(.,
        culm_count,
        by.x="from_node",
        by.y="id",
        all=TRUE) %>%
  rename(culmulative_accessibility = "charge_points") %>%
st_as_sf()


# Summarise the average distances for each by DeSO
avg_dist_deso <- joined_deso.nodes %>% as_tibble() %>% 
  group_by(deso) %>% 
  summarise(nodes = n(),
            # remove NA values from the mean to avoid an average NA result
            avg_dijk_dist = mean(dijkstras_distance, na.rm=TRUE),
            avg_travel_time = mean(travel_time),
            avg_culm_accessibility = mean(as.numeric(culmulative_accessibility), na.rm=TRUE),
            #avg_euc_dist = mean(knn_distance, na.rm=TRUE),
            avg_accessibility = mean(potential_accessibility, na.rm=TRUE)) %>% 
  arrange(avg_accessibility)

# Join with the ReGSO data to get the associated ReGSO neighbourhood name
avg_dist_deso <- merge(avg_dist_deso, regSO_deso_table, by="deso") %>% 
  arrange((avg_accessibility))

# Merge with the Gothenburg DeSO polygons for plotting
gothenburg.subdiv.merged <- merge(gothenburg.subdiv, avg_dist_deso, by="deso", all=FALSE)

# Plot the data to validate results
ggplot() + 
  geom_sf(data = gothenburg.subdiv.merged, aes(fill=(avg_culm_accessibility)), size=0.4) +
  # Charge points
  geom_sf(data=joined_charge_points, col="blue") +
  scale_fill_distiller(palette="Oranges")

avg_dist_deso %>% mutate(avg_accessibility = (avg_accessibility)) %>% filter(deso == "1480C3220")
```

```{r plot_missings}
# Filter and plot the missing data_if any, to validate if the function worked correctly

zero_values <- joined_deso.nodes %>% 
  filter(as.numeric(dijkstras_distance) == 0)

success <- joined_deso.nodes %>%
  filter(as.numeric(dijkstras_distance) > 0) %>% mutate(id = from_node) %>% as_tibble()

missings.sum <- joined_deso.nodes %>% 
  filter(as.numeric(dijkstras_distance) == 0) %>% 
  merge(., regSO_deso_table, by="deso") %>%
  group_by(regso) %>% 
  summarise(nodes = n()) %>% 
  arrange(desc(nodes))

success.sum <- joined_deso.nodes %>% 
  filter(as.numeric(dijkstras_distance) > 0) %>% 
  merge(., regSO_deso_table, by="deso") %>%
  group_by(regso) %>% 
  summarise(nodes = n()) %>% 
  arrange(desc(nodes))

got_streets_nodes <- got_streets_net %>% activate(nodes) %>% as_tibble() %>% mutate(id = as.numeric(id))

missings <- left_join(got_streets_nodes, success, keep = TRUE) %>% 
  filter(is.na(from_node)) %>% 
  st_filter(., gothenburg.subdiv) %>% mutate(id = id.x)

ggplot() + 
 # geom_sf(data = got_streets_net %>% activate(edges) %>% as_tibble() %>% st_as_sf(), size=0.4, col="grey") +
  #geom_sf(data = success, aes(fill=(nodes)), size=0.4) +
  # DeSO Subdivisions
  geom_sf(data = gothenburg.subdiv, alpha=0.3, linewidth=0.6, colour="#8778D7", fill="#90C59B") + 
  # Charge points
  geom_sf(data=joined_charge_points, col="blue") +
  geom_sf(data = missings, size=0.4, col="red") +
  #geom_sf(data = main_streets$osm_lines %>% select(highway), size=0.4, col="black") +
  scale_fill_distiller(palette = "Oranges")
```

```{r plot_avg_distance_deso, eval=TRUE, include=TRUE}

### Density plot
gothenburg.subdiv.merged %>% as_tibble() %>% 
  ggplot() + geom_density(aes(avg_culm_accessibility)) + 
  labs(title="Breakdown distance to public charging points",
       subtitle = "Density",
       fill = "Distance",
       x="Average opportunity",
       y="") +
  theme_light()

gothenburg.subdiv.merged %>% arrange(desc(avg_culm_accessibility))
```

## Analysis

### DeSO subdivision demographics

```{r load_demographic_data}
# Order the subdivisions by Regso
gothenburg.subdiv.merged <- gothenburg.subdiv.merged %>% arrange(regso)
# Get a list of ReGSO data
regso.list <- avg_dist_deso %>% select(deso, regso)
# Read csvs for deso data per demographic
deso.income <- read_csv("data/income_demographics_deso.csv")
deso.foreignborn <- read_csv("data/foreignborn_demographics_deso.csv")
deso.education <- read_csv("data/education_demographics_deso.csv")
deso.housing <- read_csv("data/housing_demographics_deso.csv")
deso.cars <- read_csv("data/cars_demographics_deso.csv")
deso.age <- read_csv("data/age_demographics_deso.csv")
deso.households <- read_csv("data/households_demographics_deso.csv")
```

```{r clean_demographic_data}
# Cleaning Deso data
deso.foreignborn <- deso.foreignborn %>% 
  mutate(swedish = swedish / total, foreign = foreign / total) %>% 
  select(-total) %>%
  filter(deso %in% regso.list$deso)

deso.income <- deso.income %>% 
  select(deso, `Median income tkr`) %>%
  filter(deso %in% regso.list$deso)

deso.education <- deso.education %>% 
  filter(deso %in% regso.list$deso) %>%
  mutate(total = rowSums(.[, -1]),
         # Define higher education
         higher_education = (post_gymnasium_less_than_3 + post_gymnasium_more_than_3) / total,
         # define lower education
         lower_education = (middle_school + gymnasium) / total,
         education_missing = education_missing / total) %>%
  select(deso, higher_education, lower_education, education_missing)

deso.housing <- deso.housing %>% 
  filter(deso %in% regso.list$deso) %>%
  select(deso, hyresrätt, bostadsrätt, äganderätt) %>%
  filter(deso %in% regso.list$deso) %>%
  mutate(total = rowSums(.[, -1]),
         rental = hyresrätt / total,
         condominium = bostadsrätt / total,
         housing = äganderätt / total) %>%
  select(deso, rental, condominium, housing)

deso.cars <- deso.cars %>%
  filter(deso %in% regso.list$deso) %>%
  mutate(cars_on_road = bilar_i_trafik) %>%
  select(deso, cars_on_road)

deso.age <- deso.age %>% 
  filter(deso %in% regso.list$deso) %>%
  # Create percentage of ages
  mutate(across(colnames(deso.age[,3:19]), function(x) x/total))

deso.pop <- deso.age %>% 
  filter(deso %in% regso.list$deso) %>% 
  mutate(pop = total, 
         ages = list(data_frame(across(colnames(deso.age[,3:19]))))) %>% 
  select(deso, pop) # ages

deso.households <- deso.households %>%
  filter(deso %in% regso.list$deso) %>% 
  select(deso, total_households) 

deso_aream2 <- gothenburg.subdiv %>% as_tibble() %>% 
  mutate(area_m2 = as.double(area)) %>% 
  select(deso, area_m2)
```

```{r combine_demographic_data}
# Combine demographic data with distances by DeSO subdivision
deso.demographics <- deso_aream2 %>%
  merge(., deso.income) %>%
  merge(., avg_dist_deso, by="deso") %>%
  merge(., deso.pop, by="deso") %>%
  merge(., deso.households, by="deso") %>%
  merge(., deso.foreignborn, by="deso") %>%
  merge(., deso.education, by="deso") %>%
  merge(., deso.housing, by="deso") %>%
  merge(., deso.cars, by="deso") %>%
  # Calculate average cars per household
  mutate(cars_per_household = cars_on_road / total_households) %>%
  select(deso, regso, nodes, avg_accessibility, avg_dijk_dist,  everything()) %>%
  arrange(desc(avg_accessibility))

#view(deso.demographics.rentals)

deso.demographics.WOMajorityHouses <- deso.demographics %>%
  # Filter out desos with majority houses
  filter(housing < 0.5)

deso.demographics.rentals <- deso.demographics %>%
  # Filter out desos with majority houses
  filter(rental > 0.50)

deso.demographics.owner.occupied <- deso.demographics %>%
filter(housing >= 0.75 | condominium >= 0.75)

# # Write files to csv if needed
# write_csv(deso.demographics %>% select(-ages), "data/deso_demographics.csv")
# write.csv(deso.demographics.rentals %>% select(-ages), "data/deso_demographics_rentals.csv")

# List of problem areas in Gothenburg as listed by the Swedish Police
# https://goteborg.se/wps/portal/enhetssida/statistik-och-analys/geografi/utsatta-omraden
# Utsatt område: Gårdsten och Hisings Backa; Riskområde (mellannivå, område som riskerar att bli särskilt utsatt): Biskopsgården, Tynnered/Grevegården/Opaltorget: Särskilt utsatt område: Bergsjön, Lövgärdet, Hammarkullen och Hjällbo
utsatta_områden <- tibble(neighbourhood = c("Bergsjön", "Biskopsgården", "Hammarkullen", "Hjällbo", "Lövgärdet", "Tynnered", "Gårdsten", "Hisings Backa"), 
                          risk_level = c(3, 2, 3, 3, 3, 2, 1, 1),
                          latitude = c(57.7510918,57.7269449,57.781713,57.7691985,57.815979,57.653612,57.8039034,57.7536741),
                          longitude = c(12.0688207,11.8549108,12.0309864,12.0177102,12.0391335,11.8668693,12.029557,11.9664854)
                          ) %>% st_as_sf(., coords = c("longitude", "latitude"), crs = 4326)
utsatta_områden <- utsatta_områden %>% arrange(risk_level)

# Central station
central_station <- tibble(landmark = c("Central Station"), 
                          latitude = c(57.7087873),
                          longitude = c(11.9702274)
                          ) %>% st_as_sf(., coords = c("longitude", "latitude"), crs = 4326)

```

### Linear regressions

```{r lm_models_all, eval=TRUE, include=TRUE}
# Gen the min value of accessibility after removing results with zero
min_rm_zero <- deso.demographics %>% filter(avg_accessibility > 0) %>% select(avg_accessibility) %>% min()
deso.demographics %>%  mutate(avg_culm_accessibility = sqrt(avg_culm_accessibility)) %>% select(avg_culm_accessibility) %>% min()

# Cap the outliers that fall outside the 95 
accessibility_capped <- deso.demographics$avg_accessibility
qnt <- quantile(accessibility_capped, probs=c(.25, .75), na.rm = T)
caps <- quantile(accessibility_capped, probs=c(.05, .95), na.rm = T)
H <- 1.5 * IQR(accessibility_capped, na.rm = T)
accessibility_capped[accessibility_capped < (qnt[1] - H)] <- caps[1]
accessibility_capped[x > (qnt[2] + H)] <- caps[2]

deso.demographics_na.rm <- deso.demographics %>% 
  # Set the values of Billdal to the min value excluding zero. This is to supportlog10 in the models
  mutate(avg_accessibility = accessibility_capped) %>%
  mutate(avg_accessibility = ifelse(avg_accessibility == 0, min_rm_zero, avg_accessibility)) %>% 
  rownames_to_column(., "i") #%>% 
  # Remove outlier # 43
  #filter(i != 43)

## For ease of readability it would be good to scale the average distance
model1 <- lm(sqrt(avg_culm_accessibility) ~foreign+cars_per_household,
             data = deso.demographics_na.rm)
summary(model1)

model2 <- lm(sqrt(avg_culm_accessibility)~foreign+cars_per_household+`Median income tkr`,
             data = deso.demographics_na.rm)
summary(model2)
#log10(avg_accessibility)~foreign+avg_dijk_dist+pop+nodes+housing+cars_on_road
model3 <- lm(sqrt(avg_culm_accessibility)~foreign+cars_per_household+`Median income tkr`+nodes, 
             data = deso.demographics_na.rm)
summary(model3)
```

### Multi-level model


```{r model_cleaning}
node_data <- joined_deso.nodes %>% as_tibble() %>%
  mutate(capacity = as.numeric(grouped_charge_points[match(joined_deso.nodes$to_node, grouped_charge_points$nodeId),]$capacity),
         dijkstras_distance = as.numeric(dijkstras_distance),
         travel_time = as.numeric(travel_time),
         deso = factor(deso)) %>% 
  select(deso, capacity, culmulative_accessibility, travel_time, dijkstras_distance, -geometry) %>% tibble()
node_data <- node_data %>%
   mutate_at(c(3:5), funs(c(scale(.))))
node_data %>% filter(deso == "1480A0050")
```


```{r multi_level}
model1.mm <- lmer(culmulative_accessibility ~ travel_time + dijkstras_distance + (1 | deso), data = node_data)
summary(model1.mm)
tidy(model1.mm)
get_variance_random(model1.mm)

model2.mm <- lmer(travel_time ~ dijkstras_distance + (culmulative_accessibility | deso), data = node_data)
summary(model2.mm)
tidy(model2.mm)

```

```{r}
model1 <- lm(sqrt(avg_culm_accessibility) ~cars_per_household+`Median income tkr`+nodes,
             data = deso.demographics_na.rm)
summary(model1)

new_data <- deso.demographics_na.rm %>% select(foreign, `Median income tkr`, cars_per_household, nodes, housing) # Provide new data for prediction
predicted_new <- predict(model1, newdata = new_data)

# Create a scatter plot with separate points for original and predicted values
ggplot() +
  geom_histogram(data = deso.demographics_na.rm, aes(x=avg_culm_accessibility), fill="light blue") +
  geom_histogram(data = tibble(value = predicted_new), aes(x=value), fill="red", alpha=0.6) +
  labs(x = "Values", y = "Values", title = "Original vs. Predicted Values") +
  theme_minimal()

median(predicted_new)
```


```{r linear_regression.weighted}
wt.1 <- 1 / lm(abs(model1$residuals) ~ model1$fitted.values)$fitted.values^2

model1.wt <- lm(sqrt(avg_culm_accessibility)~foreign+cars_per_household,  
             data = deso.demographics_na.rm, weights=wt.1)
summary(model1.wt)

wt.2 <- 1 / lm(abs(model2$residuals) ~ model2$fitted.values)$fitted.values^2

model2.wt <- lm(sqrt(avg_culm_accessibility)~foreign+cars_per_household+`Median income tkr`,  
             data = deso.demographics_na.rm, weights=wt.2)
summary(model2.wt)

wt.3 <- 1 / lm(abs(model3$residuals) ~ model3$fitted.values)$fitted.values^2

model3.wt <- lm(sqrt(avg_culm_accessibility)~foreign+cars_per_household+`Median income tkr`+nodes,  
             data = deso.demographics_na.rm, weights=wt.3)
summary(model3.wt, diagnostics=TRUE)
```

```{r linear_regression.travel}
model1.time <- lm(avg_travel_time ~foreign+cars_per_household,
             data = deso.demographics_na.rm)
summary(model1.time)

model2.time <- lm(avg_travel_time~foreign+cars_per_household+`Median income tkr`,
             data = deso.demographics_na.rm)
summary(model2.time)
#log10(avg_accessibility)~foreign+avg_dijk_dist+pop+nodes+housing+cars_on_road
model3.time <- lm(avg_travel_time~foreign+cars_per_household+`Median income tkr`+nodes, 
             data = deso.demographics_na.rm)
summary(model3.time)
```

```{r linear_regression.weighted.travel}
time.wt.1 <- 1 / lm(abs(model1.time$residuals) ~ model1.time$fitted.values)$fitted.values^2

model1.wt.time <- lm(avg_travel_time~foreign+cars_per_household,  
             data = deso.demographics_na.rm, weights=wt.1)
summary(model1.wt.time)

time.wt.2 <- 1 / lm(abs(model2.time$residuals) ~ model2.time$fitted.values)$fitted.values^2

model2.wt.time <- lm(avg_travel_time~foreign+`Median income tkr`+cars_per_household,  
             data = deso.demographics_na.rm, weights=wt.2)
summary(model2.wt.time)

time.wt.3 <- 1 / lm(abs(model3.time$residuals) ~ model3.time$fitted.values)$fitted.values^2

model3.wt.time <- lm(avg_travel_time~foreign+`Median income tkr`+cars_per_household+nodes,  
             data = deso.demographics_na.rm, weights=wt.3)
summary(model3.wt.time, diagnostics=TRUE)
```

```{r lm.test1}
# Min/Max log accessibility
deso.demographics_na.rm %>% mutate(avg_accessibility = log10(avg_accessibility)) %>% select(avg_accessibility) %>% max()
deso.demographics_na.rm %>% mutate(avg_accessibility = log10(avg_accessibility)) %>% select(avg_accessibility) %>% min()

# Confidence intervals
confint(model1.wt)

deso.demographics_na.rm %>% arrange(desc(avg_culm_accessibility)) %>% select(avg_culm_accessibility) %>% summarize(mean = mean(avg_culm_accessibility))
plot(model1)
```

```{r lm.test2}
# Homoscedasticity test
ggplot(data = deso.demographics_na.rm, aes(x = fitted(model1.wt), y = resid(model1.wt))) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE, linetype = "dashed") +
  labs(x = "Fitted Values", y = "Residuals") +
  ggtitle("Residuals vs Fitted Values") +
  theme(text = element_text(size = 12, family = "Cambria")) + theme_minimal()

# -- Breusch-Pagan test # -- Breusch-Pagan test # -- Breusch-Pagan test 
# https://sscc.wisc.edu/sscc/pubs/RegDiag-R/homoscedasticity.html
# All non-weighted LR pass the HSC test, but only model 3 of the weighted model passes
ncvTest(model3.wt)

# Endogeneity, Wald test
# A Wald test can be used to test if one or more parameters in a model are equal to certain values.
model1_wt.lv <- ivreg(avg_culm_accessibility~foreign+cars_per_household,  
             data = deso.demographics_na.rm, weights=wt.1)
summary(model1_wt.lv)

model2_wt.lv <- ivreg(avg_culm_accessibility~foreign+`Median income tkr`+cars_per_household,  
             data = deso.demographics_na.rm, weights=wt.2)
summary(model2_wt.lv)

model3_wt.lv <- ivreg(avg_culm_accessibility~foreign+`Median income tkr`+cars_per_household+nodes,  
             data = deso.demographics_na.rm, weights=wt.3)

summary(model3_wt.lv)

#Outliers: car
car::outlierTest(model1)
#Outliers: Cooks distance
cooksd <- cooks.distance(model1)
influential <- as.numeric(names(cooksd)[(cooksd > 4*mean(cooksd, na.rm=T))])  # influential row numbers
tail(deso.demographics_na.rm[influential, ])
plot(cooksd, pch="*", cex=2, main="Influential Obs by Cooks distance")  #plot cook's distance
abline(h = 4*mean(cooksd, na.rm=T), col="red")  # add cutoff line
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4*mean(cooksd, na.rm=T),names(cooksd),""), col="red")  # add labels

# Multicollinearity : VIF values
# https://www.statology.org/multicollinearity-in-r/
# VIF = 1: There is no correlation between a given predictor variable and any other predictor variables in the model.
# VIF between 1 and 5: There is moderate correlation between a given predictor variable and other predictor variables in the model.
# VIF > 5: There is severe correlation between a given predictor variable and other predictor variables in the model.
vif(model1)
vif(model2)
vif(model3)
vif(model1.wt)
vif(model2.wt)
vif(model3.wt)

## Normality of residuals
ols_plot_resid_qq(model3.wt)
ols_plot_resid_fit(model3.wt)
ols_plot_resid_hist(model3.wt)
ols_test_correlation(model3.wt)
plot(model3.wt, 5)
```


```{r lm_models_rental_areas, eval=TRUE, include=TRUE}
model1.rentals <- lm((avg_dijk_dist / 1000)~foreign+avg_accessibility+nodes+housing,  
             data = deso.demographics.rentals)

model2.rentals <- lm((avg_dijk_dist / 1000)~foreign+avg_accessibility+nodes+housing+`Median income tkr`,
             data = deso.demographics.rentals)
summary(model2.rentals)
model3.rentals <- lm((avg_dijk_dist /1000)~foreign+avg_accessibility+nodes+housing+total_households+cars_on_road,
             data = deso.demographics.rentals)
summary(model3.rentals)
```

```{r plot_demographic_results, eval=TRUE, include=TRUE}
ggplot(data = deso.demographics_na.rm, aes(x=avg_culm_accessibility, y=`Median income tkr`)) + 
  geom_point(aes(color=ifelse(foreign > 0.49, "foreign majority", "swedish majority"))) +
  labs(color="Swedish vs foreign")
  #scale_x_continuous(limits = c(0, 40))
```

```{r plot_demographic_results.rentals, eval=TRUE, include=TRUE}
# Plot rental-majority DeSOs based on dijkstras shortest distance to charge point
ggplot() + 
  geom_sf(data = gothenburg.subdiv.merged %>% filter(deso %in% deso.demographics.rentals$deso), aes(fill=avg_culm_accessibility), size=0.4) +
  scale_fill_distiller(palette = "Oranges", na.value = "brown")

# View data as table 
gothenburg.subdiv.merged %>% filter(deso %in% deso.demographics.rentals$deso) %>% 
  arrange(avg_culm_accessibility) %>% view()
```

### PCA analysis

<https://www.datacamp.com/tutorial/pca-analysis-r>

#### All subdivisions

```{r setup_pca_matrix.all}
set.seed(1234)

#### PCA and Correlations matrix
deso.demographics.pca <- deso.demographics %>% 
  rename(Population = "pop",
         `Higher education` = "higher_education",
         `Lower education` = "lower_education",
         `Charge point accessibility` = "avg_culm_accessibility",
         `Shortest distance` = "avg_dijk_dist",
          Rental = "rental",
          Housing = "housing",
          Condominium = "condominium",
          Area = "area_m2",
         #`Charge point accessibility` = "avg_accessibility",
         `Foreign background` = "foreign",
         `Swedish background` = "swedish",
         `Cars per household` = "cars_per_household",
         `Registered cars` = "cars_on_road",
         `Education missing` = "education_missing",
         `Households` = "total_households") %>%
  select(-deso, -regso, -nodes, -avg_accessibility)

# Scale the values to prevent bias
deso.demographics.normalized <- scale(deso.demographics.pca)

# Correlation matrix
corr_matrix <- cor(deso.demographics.normalized)

```

#### Majority rental subdivisions

```{r setup_pca_matrix.rentals}
#### PCA and Correlations matrix
deso.demographics.pca <- deso.demographics.rentals %>% select(-deso, -regso, -nodes, -avg_accessibility)
deso.demographics.normalized <- scale(deso.demographics.pca)
corr_matrix <- cor(deso.demographics.normalized)
```

```{r setup_pca_matrix.owner_occupied}
#### PCA and Correlations matrix
deso.demographics.pca <- deso.demographics.owner.occupied %>% select(-deso, -regso, -nodes, -avg_accessibility)
deso.demographics.normalized <- scale(deso.demographics.pca)
corr_matrix <- cor(deso.demographics.normalized)
```

```{r plot_pca_eigan_values}
# Perform PCA and run analysis on variables and relations
data.pca <- princomp(corr_matrix)
summary(data.pca)
data.pca$loadings[, 1:2]
fviz_eig(data.pca, addlabels = TRUE)
fviz_pca_var(data.pca, col.var = "black")
fviz_cos2(data.pca, choice = "var", axes = 1:2)
fviz_pca_var(data.pca, 
             col.var = "contrib",
             title="",
             gradient.cols = c("#F21A00", "#EBCC2A", "#3B9AB2"),
             repel = TRUE, 
             legend.title="Contribution",
             ggtheme = theme_minimal() + theme( axis.text =  element_text(family = "Cambria"),
                            axis.title =  element_text(family = "Cambria"),
                            legend.title = element_text(family = "Cambria"),
                            legend.text = element_text(family = "Cambria")))

# Clusters
iris[, -5]
deso.demographics[, 2:5]
clusters <- deso.demographics %>% select(avg_culm_accessibility, `Median income tkr`)
cluster_scaled <- scale(clusters)
kmeans <- kmeans(cluster_scaled, 3, nstart = 20)
fviz_cluster(kmeans, clusters)

deso.demographics.clustered <- deso.demographics %>% mutate(cluster = kmeans$cluster)

ggplot(data=deso.demographics.clustered) +
  geom_point(aes(x=avg_accessibility, y=`Median income tkr`, color=cluster))

cluster.1 <- deso.demographics.clustered %>% filter(cluster == 1)
cluster.2 <- deso.demographics.clustered %>% filter(cluster == 2)
cluster.3 <- deso.demographics.clustered %>% filter(cluster == 3)

stargazer::stargazer(list(cluster.1, cluster.2, cluster.3),
                       type="text", 
                       style="asr",
                       digits=2,
                       #omit.summary.stat = c("N", "Sd"), 
                       title = "DeSO demographic data for Gothenburg", 
                       notes = "Data from Statistics Sweden. Recorded 2022.")
```
